{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from src.bert_implementation import Attention, MultiHeadAttention, TwitterDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('src/tests/resources/test_data.csv')\n",
    "dataset = TwitterDataset(df.iloc[:4], df.iloc[4:6], df.iloc[6:9])\n",
    "expected_sentiment_list = ['UNK', 'negative', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test_switch_dataset():\n",
    "    # test len of the train dataset\n",
    "    assert len(dataset) == 4\n",
    "\n",
    "    # test len of the eval dataset\n",
    "    dataset.switch_to_dataset('eval')\n",
    "    assert len(dataset) == 2\n",
    "\n",
    "    # test len of the test dataset\n",
    "    dataset.switch_to_dataset('test')\n",
    "    assert len(dataset) == 3\n",
    "\n",
    "    # test len of the test dataset\n",
    "    try:\n",
    "        dataset.switch_to_dataset('test1')\n",
    "        assert False\n",
    "    except ValueError:\n",
    "        assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test___init_sentiment_vocab():\n",
    "    err = \"these two lists must be equal\"\n",
    "    assert sorted(dataset.st_voc) == expected_sentiment_list, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test_get_sentiment_i():\n",
    "    dataset.st_voc = expected_sentiment_list\n",
    "    assert dataset.get_sentiment_i('negative') == 1\n",
    "    assert dataset.get_sentiment_i('negative1') == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test___init_vocab():\n",
    "    dataset___init_vocab = TwitterDataset(df.iloc[2:4], [], [])\n",
    "    err = \"these vocabulary must be equals\"\n",
    "    expected_voc = [ 'UNK', 'SOS', 'EOS', 'MASK', '-PRON-', 'boss', 'be', 'bully',\n",
    "                        '...', 'what', 'interview', '!', 'leave', 'alone']\n",
    "    assert sorted(dataset___init_vocab.vocabulary['tokens']) == sorted(expected_voc), err\n",
    "    assert dataset___init_vocab.vocabulary['max_seq_len'] == 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test_vectorize():\n",
    "    dataset_vectorize = TwitterDataset(df.iloc[0:0], [], [])\n",
    "    dataset_vectorize.vocabulary['tokens'] = ['of', 'SOS', 'MASK', 'high',\n",
    "                                                'both', 'EOS', 'sooo', '-PRON-', 'UNK']\n",
    "    dataset_vectorize.vocabulary['max_seq_len'] = 5\n",
    "\n",
    "    err = \"these vectors must be equals\"\n",
    "\n",
    "    # vector : ['SOS', 'sooo', 'high', 'EOS', 'MASK']\n",
    "    expected_v_1 = [1, 6, 3, 5, 2]\n",
    "    # vector : ['SOS', 'both', 'of', 'you', 'EOS']\n",
    "    expected_v_2 = [1, 4, 0, 7, 5]\n",
    "    observed_v_1 = dataset_vectorize.vectorize(\"Sooo high\")\n",
    "    observed_v_2 = dataset_vectorize.vectorize(\"Both of you\")\n",
    "\n",
    "    assert len(observed_v_1) == len(observed_v_2)\n",
    "    assert expected_v_1 == observed_v_1, err\n",
    "    assert expected_v_2 == observed_v_2, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test__get_item__():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def test_attention():\n",
    "    err = \"the size must be equal to this set\"\n",
    "    att = Attention(4,3)\n",
    "    test_tensor = torch.rand(3,2,4)\n",
    "    assert att(test_tensor).shape == (3,2,3), err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multi_head_attention():\n",
    "    err = \"the size must be equal to this set\"\n",
    "    att = MultiHeadAttention(8,4,3)\n",
    "    test_tensor = torch.rand(3,2,4)\n",
    "    assert att(test_tensor).shape == (3,2,4), err"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
